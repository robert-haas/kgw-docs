{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62ed678-bd1e-4d71-a051-8b0d0a1cff07",
   "metadata": {},
   "source": [
    "# Quickstart example\n",
    "\n",
    "The following provides a minimal example for getting started with the package [kgw](https://robert-haas.github.io/kgw-docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0600de-dbc0-433e-9e3a-5cebfdc669d2",
   "metadata": {},
   "source": [
    "## Load the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293b7683-931d-4cfb-b4d9-19a225b253e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kgw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b52120-f38c-469d-83de-ae0d9f1a9f38",
   "metadata": {},
   "source": [
    "## Define a minimal workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd10c4d4-06b3-4353-b7db-26f924182a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hald = kgw.biomedicine.Hald(version=\"latest\", workdir=\"a_user_chosen_directory\")\n",
    "hald.to_graphml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24577ae-a9b7-4dc8-8952-5189de1269fd",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829208bc-de79-401d-bb3a-b7d108e62654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log of performed tasks\n",
      "======================\n",
      "\n",
      "2024-10-11 01:18:32  \u001b[94mStarted\u001b[0m   CreateDirectory(dirpath=a_user_chosen_directory/hald_v6/downloads)\n",
      "2024-10-11 01:18:32  \u001b[94mStarted\u001b[0m   CreateDirectory(dirpath=a_user_chosen_directory/hald_v6/results)\n",
      "2024-10-11 01:18:32  \u001b[92mFinished\u001b[0m  CreateDirectory(dirpath=a_user_chosen_directory/hald_v6/downloads)\n",
      "2024-10-11 01:18:32  \u001b[92mFinished\u001b[0m  CreateDirectory(dirpath=a_user_chosen_directory/hald_v6/results)\n",
      "2024-10-11 01:18:32  \u001b[94mStarted\u001b[0m   DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Relation_Info.json)\n",
      "2024-10-11 01:18:32  \u001b[94mStarted\u001b[0m   DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Entity_Info.json)\n",
      "2024-10-11 01:19:46  \u001b[92mFinished\u001b[0m  DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Relation_Info.json)\n",
      "2024-10-11 01:19:46  \u001b[94mStarted\u001b[0m   FetchEdgesFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:19:46  \u001b[92mFinished\u001b[0m  FetchEdgesFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:21:44  \u001b[92mFinished\u001b[0m  DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Entity_Info.json)\n",
      "2024-10-11 01:21:44  \u001b[94mStarted\u001b[0m   FetchNodesFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:21:44  \u001b[92mFinished\u001b[0m  FetchNodesFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:21:44  \u001b[94mStarted\u001b[0m   CreateSqliteFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:22:19  \u001b[92mFinished\u001b[0m  CreateSqliteFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:22:19  \u001b[94mStarted\u001b[0m   CreateGraphMlFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "2024-10-11 01:23:02  \u001b[92mFinished\u001b[0m  CreateGraphMlFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "\n",
      "\n",
      "Summary of workflow results\n",
      "===========================\n",
      "\n",
      "Scheduled 8 tasks of which:\n",
      "* 8 ran successfully:\n",
      "    - 2 CreateDirectory(dirpath=a_user_chosen_directory/hald_v6/downloads,a_user_chosen_directory/hald_v6/results)\n",
      "    - 1 CreateGraphMlFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "    - 1 CreateSqliteFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "    - 2 DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Entity_Info.json) and DownloadFile(dirpath=a_user_chosen_directory/hald_v6/downloads, filename=Relation_Info.json)\n",
      "    - 1 FetchEdgesFile(dirpath=a_user_chosen_directory/hald_v6, version=6)\n",
      "    ...\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n"
     ]
    }
   ],
   "source": [
    "status = kgw.run(hald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b8e1e5-241f-4838-a620-eb7b425cbe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The workflow fully succeeded: True\n"
     ]
    }
   ],
   "source": [
    "print(\"The workflow fully succeeded:\", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb01796f-f78f-4bfe-96b5-71025c5eb1c4",
   "metadata": {},
   "source": [
    "## Inspect the results\n",
    "\n",
    "Running the workflow generates several directories and files within the user-defined working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd7fe9b-e92f-4b54-ae06-628113d7030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_user_chosen_directory/\n",
      "  hald_v6/\n",
      "    downloads/\n",
      "      \u001b[91mEntity_Info.json\u001b[0m\n",
      "      \u001b[91mRelation_Info.json\u001b[0m\n",
      "    results/\n",
      "      \u001b[92mkg.graphml\u001b[0m\n",
      "      \u001b[92mkg.sqlite\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def inspect_directory(path):\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    for root, _, files in sorted(os.walk(path)):\n",
    "        dir_name = os.path.basename(root)\n",
    "        level = root.replace(path, '').count(os.sep)\n",
    "        color = RED if dir_name == \"downloads\" else GREEN\n",
    "        dir_indent = ' ' * 2 * level\n",
    "        file_indent = ' ' * 2 * (level + 1)\n",
    "        print(f\"{dir_indent}{dir_name}/\")\n",
    "        for file_name in files:\n",
    "            print(f\"{file_indent}{color}{file_name}{RESET}\")\n",
    "\n",
    "inspect_directory(\"a_user_chosen_directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50868d21-d361-4253-9c71-b3a9759e0d77",
   "metadata": {},
   "source": [
    "## Interpret them\n",
    "\n",
    "- The workflow definition at the beginning means that the knowledge graph of the project HALD should be converted to a GraphML file. This requires that the original files are downloaded from the project's web repository and then converted step by step into the desired output format.\n",
    "- Running the workflow auto-generates a directory structure in the user-defined working directory `a_user_chosen_directory`. First there is a subdirectory for the project (HALD) in its chosen version (\"latest\" = version 6 at time of writing) named `hald_v6`, so that no collisions between projects or versions can happen. Each directory of such a kind then has two further subdirectories to separate fetched from generated files:\n",
    "  - The `downloads` directory contains all files fetched from the project's web repository in unmodified form. In this case these are two JSON files shown in red. The number and types of files varies between projects because there is no widely accepted standard for how to encode a knowledge graph.\n",
    "  - The `results` directory contains all files derived from the raw downloads. In this case these are two files shown in green, although only one output was specified in the workflow in the beginning.\n",
    "    - `kg.sqlite` is a file-based SQLite database, which serves as intermediate format that is used as common basis for all conversions and analyses supported by this package. For this reason, it has to be generated before producing any other outputs.\n",
    "    - `kg.graphml` is the HALD knowledge graph in the desired output format [GraphML](https://en.wikipedia.org/wiki/GraphML).\n",
    "- It is possible to define a larger workflow that can include multiple projects, versions and output formats. Internally, the Python package [luigi](https://github.com/spotify/luigi) is used to build a dependency graph, which contains all tasks that need to be run in order to produce the desired output files. The local inputs and outputs of each task along the way are well defined, so the scheduler can automatically run them as early as possible and often in parallel. For example, all downloads are independent, so they don't need to wait for each other, but some downstream conversions require multiple input files, so they have to wait for a specific subset of downloads or other conversions to be finished. The overall process can be tracked through messages that are written whenever a task starts or is finished. If everything worked, the `run` function returns `True`. If some part failed, e.g. due to a failed web connection, the other parts are attempted to be finished as far as possible, but a `False` is returned to make clear that something is missing. The workflow can then be restarted and will not begin again from zero, but rather will only run tasks that have not produced their local outputs yet. Some work may be lost anyways, e.g. when a specific conversion was interrupted in the middle the progress is usually lost, but downloads will attempt to continue from partial files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
